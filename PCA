PCA
优点：降低数据复杂性，识别最重要的多个特征
缺点：不一定需要，且可能损失有用信息

process：
1. 原始数据集减去每列特征均值meanVal得到新new_mat；
2. 计算new_mat的协方差矩阵covMat;
3. 根据linalg.eig计算协方差矩阵的特征值和特征向量Vec;
4. 利用argsort()函数对特征值进行由小到大的排序得到序号；
5. 取逆序的topN个index对应的特征向量select_vec;
6. 重构数据  低维度数据 low_dataset=np.dot(new_mat,select_vec)
降维数据集 new_dataset=np.dot(low_dataset,select_vec.T)+meanVal.

import numpy as np

f=open('testSet.txt')
dataset=[]
for elem in f.readlines():
    data=elem.strip().split()
    data=[float(k) for k in data]
    dataset.append(data)
dataset=np.array(dataset)
def pca(dataMat,k=500):
    meanVals=np.mean(dataMat,axis=0)  #对每一列求平均值，因为协方差的计算中需要减去均值
    meanRemoved=dataMat-meanVals
    covMat=np.cov(meanRemoved,rowvar=0)  #cov()计算方差
    eigVals,eigVects=np.linalg.eig(covMat)  #利用numpy中寻找特征值和特征向量的模块linalg中的eig()方法
    eigValInd=np.argsort(eigVals)  #对特征值eigVals从小到大排序
    eigValInd=eigValInd[:-k:-1] #从排好序的特征值，从后往前取k个，这样就实现了特征值的从大到小排列
    redEigVects=eigVects[:,eigValInd]   #返回排序后特征值对应的特征向量redEigVects（主成分）
    lowDDataMat=np.dot(meanRemoved,redEigVects) #将原始数据投影到主成分上得到新的低维数据lowDDataMat
    reconMat=np.dot(lowDDataMat,redEigVects.T)+meanVals   #得到重构数据reconMat
    return lowDDataMat,reconMat
lowDataset,recMat=pca(dataset)
